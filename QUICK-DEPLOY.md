# –ë—ã—Å—Ç—Ä–∞—è —à–ø–∞—Ä–≥–∞–ª–∫–∞: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ immers.cloud

**–°–µ—Ä–≤–µ—Ä**: 195.209.210.16  
**–ü—Ä–æ–µ–∫—Ç**: `/opt/engineering_AI` (–∏–ª–∏ `/root/engineering_AI`)

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–ø–æ—à–∞–≥–æ–≤–æ)

### 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–µ—Ä–≤–µ—Ä—É
```bash
ssh immers-cloud
# –∏–ª–∏
ssh root@195.209.210.16
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
```bash
apt update && apt upgrade -y
apt install -y git docker.io docker-compose
systemctl enable docker && systemctl start docker

# NVIDIA Container Toolkit (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–ª—è GPU)
# –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –æ—à–∏–±–∫–∞ "unknown or invalid runtime name: nvidia", –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# –ü—Ä–æ–≤–µ—Ä–∫–∞
docker run --rm --runtime=nvidia --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

### 3. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
```bash
cd /opt
git clone <repository-url> engineering_AI
cd engineering_AI
```

### 4. –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞
```bash
cat > .env << 'EOF'
OLLAMA_NUM_GPU=1
OLLAMA_GPU_LAYERS=35
NVIDIA_VISIBLE_DEVICES=all
BASE_MODEL=llama3.1:8b
API_HOST=0.0.0.0
API_PORT=8080
OLLAMA_BASE_URL=http://ollama:11434
EOF
```

### 5. –ó–∞–ø—É—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞

**–í–ê–ñ–ù–û**: –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—à–∏–±–∫–∞ "Permission denied", –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `sudo`:
- `sudo docker-compose up -d ollama`
- –ò–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –≥—Ä—É–ø–ø—É docker: `sudo usermod -aG docker $USER` –∏ –ø–µ—Ä–µ–ª–æ–≥–∏–Ω—å—Ç–µ—Å—å

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏
docker compose version || docker-compose --version

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ Docker
docker ps || sudo docker ps

# –ó–∞–ø—É—Å–∫ Ollama (–¥–æ–±–∞–≤—å—Ç–µ sudo –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
docker compose up -d ollama || docker-compose up -d ollama || sudo docker-compose up -d ollama

# –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ (–ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã)
while ! (docker compose ps ollama 2>/dev/null || docker-compose ps ollama 2>/dev/null || sudo docker-compose ps ollama 2>/dev/null) | grep -q healthy; do sleep 2; done

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10-30 –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)
# –í–ê–ñ–ù–û: –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π: chmod +x ollama/scripts/create_models.sh
chmod +x ollama/scripts/create_models.sh
docker compose run --rm ollama-init || docker-compose run --rm ollama-init || sudo docker-compose run --rm ollama-init

# –ó–∞–ø—É—Å–∫ Backend
docker compose up -d backend || docker-compose up -d backend || sudo docker-compose up -d backend
```

### 6. –ü—Ä–æ–≤–µ—Ä–∫–∞
```bash
# –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤
docker compose ps

# Health check
curl http://localhost:8080/health

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://localhost:8080/models

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
docker exec -it ollama nvidia-smi
```

---

## üìã –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞–º–∏

**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `docker-compose` (—Å –¥–µ—Ñ–∏—Å–æ–º) –µ—Å–ª–∏ `docker compose` –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç**

```bash
# –°—Ç–∞—Ç—É—Å
docker compose ps || docker-compose ps

# –õ–æ–≥–∏
docker compose logs -f || docker-compose logs -f
docker compose logs -f ollama || docker-compose logs -f ollama
docker compose logs -f backend || docker-compose logs -f backend

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫
docker compose restart || docker-compose restart
docker compose restart ollama || docker-compose restart ollama

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker compose down || docker-compose down

# –ó–∞–ø—É—Å–∫
docker compose up -d || docker-compose up -d
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
```bash
# GPU
watch -n 1 nvidia-smi

# –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
docker stats

# –î–∏—Å–∫
df -h
docker system df
```

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ
```bash
cd /opt/engineering_AI
docker compose down || docker-compose down
git pull
docker compose build backend || docker-compose build backend
docker compose up -d || docker-compose up -d
```

---

## üîß –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### GPU –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
```bash
nvidia-smi
docker exec -it ollama nvidia-smi
systemctl restart docker
docker compose restart ollama || docker-compose restart ollama
```

### –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è
```bash
docker compose logs ollama-init || docker-compose logs ollama-init
docker compose run --rm ollama-init || docker-compose run --rm ollama-init
docker exec -it ollama ollama list
```

### Backend –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
```bash
docker compose ps || docker-compose ps
docker compose logs backend || docker-compose logs backend
curl http://localhost:8080/health
```

---

## üìù –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- `SERVER-SETUP.md` - –ü–æ–¥—Ä–æ–±–Ω–∞—è –ø–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
- `DEPLOYMENT.md` - –û–±—â–µ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é

---

**–í–µ—Ä—Å–∏—è**: 1.0

