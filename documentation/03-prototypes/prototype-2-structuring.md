# Прототип 2: Структурирование данных и текстовые запросы

**Цель**: Проверка способности объединять и организовывать табличные и текстовые данные, а также обработки текстовых запросов пользователей  
**Статус**: В разработке  
**Приоритет**: Критический  

---

## Описание

Прототип преобразует неструктурированные данные в машиночитаемые форматы с применением алгоритмов группировки и классификации, а также обеспечивает обработку текстовых запросов пользователей и формирование ответов в удобном формате.

### Связь с пользовательскими сценариями (UC)
- UC-05: Формирование отчетов в Excel по шаблонам подразделений (ПТО/Сметный отдел)
- UC-02: Обработка текстовых запросов (использование базы знаний, подготовленной P1)
- UC-04b: Нормализация смет до унифицированной модели Estimate и проверок (totals/units/RD‑cipher)

### Входные данные
- Извлеченный текст из OCR
- Табличные данные из PDF
- Текстовые документы
- Метаданные документов
- Текстовые запросы пользователей
- База знаний из обученной системы

### Выходные форматы
- **Excel (XLSX)** - основной формат для структурированных данных
- **JSON** - структурированные данные для API
- **CSV** - табличные данные для совместимости
- **XML** - иерархические данные
- **Текстовые ответы** - ответы на пользовательские запросы
- **Excel отчеты** - сформированные отчеты по запросам

### Роли и подразделения
- ПТО: сводные спецификации, унификация
- Сметный отдел: нормализованные сметы, бюджетирование
- Пользователь системы: получение отчётов по запросам

### Дополнительно (расширение P2)
- Шаблон‑специфичное форматирование XLSX; проверка структуры/стилей
- Пост‑обработка смет (перенос формул/схлопывание/агрегации), аудит валидаций

---

## План реализации

### Этап 1: Анализ данных (2 дня)
- [ ] Изучение структуры документов заказчика
- [ ] Выявление паттернов в данных
- [ ] Определение полей для извлечения
- [ ] Анализ типов текстовых запросов

### Этап 2: Алгоритмы структурирования (4 дня)
- [ ] Парсинг таблиц из PDF
- [ ] Извлечение ключевых полей
- [ ] Группировка связанных данных
- [ ] Валидация извлеченных данных

### Этап 3: Обработка текстовых запросов (4 дня)
- [ ] Реализация NLP-модуля для понимания запросов
- [ ] Создание системы поиска по базе знаний
- [ ] Разработка алгоритмов формирования ответов
- [ ] Интеграция с обученной системой

### Этап 4: Форматы вывода (2 дня)
- [ ] Генерация JSON-схем
- [ ] Приоритетный экспорт в Excel (XLSX)
- [ ] Создание шаблонов данных
- [ ] Тестирование совместимости

### Этап 5: Интеграция (2 дня)
- [ ] Связка с OCR-модулем
- [ ] Интеграция с системой обучения
- [ ] Обработка ошибок
- [ ] Оптимизация производительности

---

## Критерии успеха

- **Полнота извлечения**: ≥90% ключевых полей
- **Корректность структурирования**: ≥95%
- **Время обработки**: ≤15 сек на документ
- **Поддержка форматов**: JSON, CSV, XLSX, XML
- **Точность ответов на запросы**: ≥85%
- **Время ответа на запрос**: ≤5 сек
- **Качество Excel отчетов**: ≥90% корректных данных

---

## Технический стек

- **Парсинг**: pandas, openpyxl
- **NLP**: spaCy, NLTK, transformers
- **Валидация**: jsonschema, cerberus
- **Поиск**: Elasticsearch, FAISS
- **Excel**: openpyxl, xlsxwriter
- **Язык**: Python 3.11+
- **Контейнеризация**: Docker

---

## Алгоритмы

- **Извлечение таблиц**: Tabula-py, Camelot
- **Классификация полей**: Regex + ML
- **Группировка данных**: Clustering algorithms
- **Валидация**: Rule-based + ML models
- **Понимание запросов**: BERT, RoBERTa для NLP
- **Поиск по базе знаний**: Semantic search, vector similarity
- **Формирование ответов**: Template-based + generative models

---

## Риски

- Нестандартные форматы документов
- Сложность извлечения таблиц
- Низкое качество исходных данных
- Сложность понимания естественных запросов
- Неоднозначность пользовательских запросов
- Производительность NLP-моделей
- Качество формирования Excel отчетов

---

## Demo Script (без метрик)
1. Импорт структурированных данных из P1 (таблицы спецификаций, сметы, метаданные).
2. Нормализация смет в унифицированную модель Estimate (totals/units/RD‑cipher).
3. Конфигурация шаблонов XLSX для ПТО и Сметного отдела.
4. Генерация отчётов: выбор шаблона → структурирование → форматирование → экспорт XLSX.
5. Ответы на запросы: показ примеров UC‑02 с использованием нормализованных данных.
6. Просмотр логов валидаций (сводка проверок и корректировок).

## Acceptance Checklist (без метрик)
- [ ] Данные из P1 корректно импортированы (таблицы/сметы/метаданные).
- [ ] Сметы нормализованы: рассчитаны totals, проверены units, есть RD‑cipher.
- [ ] Отчёты XLSX формируются по шаблонам подразделений, структура и стили соблюдены.
- [ ] Запросы UC‑02 возвращают корректно структурированные данные из базы знаний.
- [ ] Логи валидаций доступны и воспроизводимы.

---

## Sample data pack (для демонстрации)
- Импорт из P1: JSON метаданных и таблиц (PDF/DWG), Estimate JSON (ARP/GSFX/XML/XLS), черновые XLS.
- Шаблоны XLSX подразделений: ПТО, Сметный отдел (эталонные файлы от заказчика).

Связанные UC: UC‑02, UC‑05, UC‑28..UC‑32, UC‑35.
